{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Importing dependencies \n",
    "library(tidyverse)\n",
    "library(caret)\n",
    "library(glmnet)\n",
    "library(pROC)\n",
    "library(rpart)\n",
    "library(rpart.plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data <- read.csv('cleaneddata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tWelch Two Sample t-test\n",
       "\n",
       "data:  tenure by PaperlessBilling\n",
       "t = -0.4041, df = 6136.8, p-value = 0.6862\n",
       "alternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n",
       "95 percent confidence interval:\n",
       " -1.4097501  0.9278837\n",
       "sample estimates:\n",
       "mean in group 1 mean in group 2 \n",
       "       32.27898        32.51991 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Convert PaperlessBilling into a factor\n",
    "data <- data %>% \n",
    "    mutate(PaperlessBilling = as.factor(PaperlessBilling))\n",
    "\n",
    "#Perform indepedendent samples t-test\n",
    "t_test_result <- t.test(tenure ~ PaperlessBilling, data = data)\n",
    "t_test_result\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is 0.6862, which represents the probability of observing a t-value as extreme (or more) as -0.4041 under the null hypothesis (There is no difference in the average tenure between the two groups). \n",
    "\n",
    "Since the p-value is greater than the typical significance level of 0.05, we fail to reject the null hypothesis. This means that there is no statistically significant evidence to suggest that there is a difference in the average tenure between customers with and without paperless billing. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To investigate if there is a significant difference in the average tenure between customers with different types of contracts, we first observe that this variable has more than 2 levels. Hence we cannot use the Welch t.test since it is desgined to compare the means of a continuous depenedent variable between two independent groups. \n",
    "\n",
    "In this case we can use one-way Analysis of Variance (ANOVA) to compare the means of a continuous dependent variable across multiple groups. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Call:\n",
       "   aov(formula = tenure ~ Contract, data = data)\n",
       "\n",
       "Terms:\n",
       "                Contract Residuals\n",
       "Sum of Squares   1962830   2273135\n",
       "Deg. of Freedom        2      7029\n",
       "\n",
       "Residual standard error: 17.98315\n",
       "Estimated effects may be unbalanced"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A anova: 2 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Df</th><th scope=col>Sum Sq</th><th scope=col>Mean Sq</th><th scope=col>F value</th><th scope=col>Pr(&gt;F)</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Contract   </th><td>   2</td><td>1962830</td><td>981414.8995</td><td>3034.736</td><td> 0</td></tr>\n",
       "\t<tr><th scope=row>Residuals  </th><td>7029</td><td>2273135</td><td>   323.3938</td><td>      NA</td><td>NA</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A anova: 2 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & Df & Sum Sq & Mean Sq & F value & Pr(>F)\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\tContract    &    2 & 1962830 & 981414.8995 & 3034.736 &  0\\\\\n",
       "\tResiduals   & 7029 & 2273135 &    323.3938 &       NA & NA\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A anova: 2 × 5\n",
       "\n",
       "| <!--/--> | Df &lt;dbl&gt; | Sum Sq &lt;dbl&gt; | Mean Sq &lt;dbl&gt; | F value &lt;dbl&gt; | Pr(&gt;F) &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| Contract    |    2 | 1962830 | 981414.8995 | 3034.736 |  0 |\n",
       "| Residuals   | 7029 | 2273135 |    323.3938 |       NA | NA |\n",
       "\n"
      ],
      "text/plain": [
       "            Df   Sum Sq  Mean Sq     F value  Pr(>F)\n",
       "Contract       2 1962830 981414.8995 3034.736  0    \n",
       "Residuals   7029 2273135    323.3938       NA NA    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data <- data %>% \n",
    "    mutate(Contract = as.factor(Contract))\n",
    "\n",
    "#Perform indepedendent samples t-test\n",
    "anova_result <- aov(tenure ~ Contract, data = data)\n",
    "anova_result\n",
    "anova_table <- summary(anova_result)\n",
    "anova_table[[1]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is 0, which is less than the typical significance level of 0.05. This means that we can reject the null hypothesis, concluding that there **is a significant difference in the average tenure between at least one pair of contract types**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A summary_emm: 3 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>contrast</th><th scope=col>estimate</th><th scope=col>SE</th><th scope=col>df</th><th scope=col>t.ratio</th><th scope=col>p.value</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>Contract1 - Contract2</td><td>-24.03672</td><td>0.5505936</td><td>7029</td><td>-43.65602</td><td>3.723799e-12</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>Contract1 - Contract3</td><td>-39.03516</td><td>0.5247681</td><td>7029</td><td>-74.38555</td><td>3.723799e-12</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>Contract2 - Contract3</td><td>-14.99844</td><td>0.6415777</td><td>7029</td><td>-23.37743</td><td>3.723799e-12</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A summary\\_emm: 3 × 6\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & contrast & estimate & SE & df & t.ratio & p.value\\\\\n",
       "  & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & Contract1 - Contract2 & -24.03672 & 0.5505936 & 7029 & -43.65602 & 3.723799e-12\\\\\n",
       "\t2 & Contract1 - Contract3 & -39.03516 & 0.5247681 & 7029 & -74.38555 & 3.723799e-12\\\\\n",
       "\t3 & Contract2 - Contract3 & -14.99844 & 0.6415777 & 7029 & -23.37743 & 3.723799e-12\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A summary_emm: 3 × 6\n",
       "\n",
       "| <!--/--> | contrast &lt;chr&gt; | estimate &lt;dbl&gt; | SE &lt;dbl&gt; | df &lt;dbl&gt; | t.ratio &lt;dbl&gt; | p.value &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 1 | Contract1 - Contract2 | -24.03672 | 0.5505936 | 7029 | -43.65602 | 3.723799e-12 |\n",
       "| 2 | Contract1 - Contract3 | -39.03516 | 0.5247681 | 7029 | -74.38555 | 3.723799e-12 |\n",
       "| 3 | Contract2 - Contract3 | -14.99844 | 0.6415777 | 7029 | -23.37743 | 3.723799e-12 |\n",
       "\n"
      ],
      "text/plain": [
       "  contrast              estimate  SE        df   t.ratio   p.value     \n",
       "1 Contract1 - Contract2 -24.03672 0.5505936 7029 -43.65602 3.723799e-12\n",
       "2 Contract1 - Contract3 -39.03516 0.5247681 7029 -74.38555 3.723799e-12\n",
       "3 Contract2 - Contract3 -14.99844 0.6415777 7029 -23.37743 3.723799e-12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(emmeans)\n",
    "estimated_means <- emmeans(anova_result, ~ Contract)\n",
    "post_hoc_result <- pairs(estimated_means, adjust = \"tukey\")\n",
    "summary(post_hoc_result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The p-values have been adjusted for multiple comparisons using the Tukey method. For all three pairwise comparisons, the p-values are extremely small (3.723799e-12), which is much lower than the typical significance level of 0.05. This means that there is a statistically significant difference in the average tenure between each pair of contract types.\n",
    "\n",
    " In conclusion, the Tukey's HSD test results indicate that there are significant differences in the average tenure between all three contract types. Customers with a month-to-month contract have a significantly lower average tenure compared to those with one-year and two-year contracts. Similarly, customers with a one-year contract have a significantly lower average tenure compared to those with a two-year contract.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this in mind, we will now attempt to identify high-risk customers with regards to churn. To do this, we will first be use the logistic regression model, which models the relationship between churn (as the dependent variable) and multiple independent variables, such as demographics, services, contract type, and billing information. Logistic regression can help us identify the most important factors that contribute to churn and estimate the likelihood of a customer churning based on these factors, as shown previously. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary of the process:\n",
    "\n",
    "Feature Selection: Identify the most important features (independent variables) that have a significant impact on the target variable (churn). We will be using the variables identified earlier.\n",
    "\n",
    "Train the Model: We will split our dataset into a training and testing set (e.g., 70% training, 30% testing). We will then train a logistic regression model on the training set using the selected features as predictors and churn as the target variable.\n",
    "\n",
    "Model Evaluation: We will then evaluate the performance of the logistic regression model on the testing set using metrics like accuracy, precision, recall, F1-score, and area under the ROC curve (AUC-ROC). \n",
    "\n",
    "Predict Churn Probability: Once the model is trained and validated, we will use it to predict the probability of churn for each customer in your dataset. This will give us a probability score between 0 and 1 for each customer.\n",
    "\n",
    "Set a Threshold: We will then determine a threshold for the churn probability above which customers will be considered high-risk. In our case, we have arbitrarily selected 0.7 as our threshold.\n",
    "\n",
    "Identify High-Risk Customers: Apply the threshold to the predicted churn probabilities to classify customers as high-risk or low-risk. Customers with churn probabilities above the threshold will be considered high-risk.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 2. Feature Selection: Correlation analysis \n",
    "data_filtered <- read.csv('df2.csv')\n",
    "\n",
    "# Add the Churn column back to the filtered dataset\n",
    "data_filtered$Churn <- data$Churn\n",
    "# Convert Churn column to binary numeric values\n",
    "data_filtered$Churn <- ifelse(data_filtered$Churn == 1, 1, 0)\n",
    "\n",
    "\n",
    "# 3. Train the Model: Split the data into training and testing sets\n",
    "set.seed(123)\n",
    "split <- createDataPartition(data_filtered$Churn, p = 0.7, list = FALSE)\n",
    "train <- data_filtered[split,]\n",
    "test <- data_filtered[-split,]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix and Statistics\n",
      "\n",
      "          Reference\n",
      "Prediction    0    1\n",
      "         0  486  272\n",
      "         1   74 1277\n",
      "                                          \n",
      "               Accuracy : 0.8359          \n",
      "                 95% CI : (0.8194, 0.8515)\n",
      "    No Information Rate : 0.7345          \n",
      "    P-Value [Acc > NIR] : < 2.2e-16       \n",
      "                                          \n",
      "                  Kappa : 0.622           \n",
      "                                          \n",
      " Mcnemar's Test P-Value : < 2.2e-16       \n",
      "                                          \n",
      "            Sensitivity : 0.8679          \n",
      "            Specificity : 0.8244          \n",
      "         Pos Pred Value : 0.6412          \n",
      "         Neg Pred Value : 0.9452          \n",
      "             Prevalence : 0.2655          \n",
      "         Detection Rate : 0.2304          \n",
      "   Detection Prevalence : 0.3594          \n",
      "      Balanced Accuracy : 0.8461          \n",
      "                                          \n",
      "       'Positive' Class : 0               \n",
      "                                          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting levels: control = 0, case = 1\n",
      "\n",
      "Setting direction: controls < cases\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 4203 × 23</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>customerID</th><th scope=col>gender</th><th scope=col>SeniorCitizen</th><th scope=col>Partner</th><th scope=col>Dependents</th><th scope=col>tenure</th><th scope=col>PhoneService</th><th scope=col>MultipleLines</th><th scope=col>InternetService</th><th scope=col>OnlineSecurity</th><th scope=col>⋯</th><th scope=col>StreamingTV</th><th scope=col>StreamingMovies</th><th scope=col>Contract</th><th scope=col>PaperlessBilling</th><th scope=col>PaymentMethod</th><th scope=col>MonthlyCharges</th><th scope=col>TotalCharges</th><th scope=col>numAdminTickets</th><th scope=col>numTechTickets</th><th scope=col>Churn</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>⋯</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>2</th><td>5575-GNVDE</td><td>2</td><td>1</td><td>1</td><td>1</td><td>34</td><td>2</td><td>1</td><td>1</td><td>3</td><td>⋯</td><td>1</td><td>1</td><td>2</td><td>1</td><td>4</td><td> 56.95</td><td>1889.50</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>7795-CFOCW</td><td>2</td><td>1</td><td>1</td><td>1</td><td>45</td><td>1</td><td>2</td><td>1</td><td>3</td><td>⋯</td><td>1</td><td>1</td><td>2</td><td>1</td><td>1</td><td> 42.30</td><td>1840.75</td><td>0</td><td>3</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>6713-OKOMC</td><td>1</td><td>1</td><td>1</td><td>1</td><td>10</td><td>1</td><td>2</td><td>1</td><td>3</td><td>⋯</td><td>1</td><td>1</td><td>1</td><td>1</td><td>4</td><td> 29.75</td><td> 301.90</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>6388-TABGU</td><td>2</td><td>1</td><td>1</td><td>2</td><td>62</td><td>2</td><td>1</td><td>1</td><td>3</td><td>⋯</td><td>1</td><td>1</td><td>2</td><td>1</td><td>1</td><td> 56.15</td><td>3487.95</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>11</th><td>9763-GRSKD</td><td>2</td><td>1</td><td>2</td><td>2</td><td>13</td><td>2</td><td>1</td><td>1</td><td>3</td><td>⋯</td><td>1</td><td>1</td><td>1</td><td>2</td><td>4</td><td> 49.95</td><td> 587.45</td><td>1</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>12</th><td>7469-LKBCI</td><td>2</td><td>1</td><td>1</td><td>1</td><td>16</td><td>2</td><td>1</td><td>3</td><td>2</td><td>⋯</td><td>2</td><td>2</td><td>3</td><td>1</td><td>2</td><td> 18.95</td><td> 326.80</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>13</th><td>8091-TTVAX</td><td>2</td><td>1</td><td>2</td><td>1</td><td>58</td><td>2</td><td>3</td><td>2</td><td>1</td><td>⋯</td><td>3</td><td>3</td><td>2</td><td>1</td><td>2</td><td>100.35</td><td>5681.10</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>15</th><td>5129-JLPIS</td><td>2</td><td>1</td><td>1</td><td>1</td><td>25</td><td>2</td><td>1</td><td>2</td><td>3</td><td>⋯</td><td>3</td><td>3</td><td>1</td><td>2</td><td>3</td><td>105.50</td><td>2686.05</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>16</th><td>3655-SNQYZ</td><td>1</td><td>1</td><td>2</td><td>2</td><td>69</td><td>2</td><td>3</td><td>2</td><td>3</td><td>⋯</td><td>3</td><td>3</td><td>3</td><td>1</td><td>2</td><td>113.25</td><td>7895.15</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>17</th><td>8191-XWSZG</td><td>1</td><td>1</td><td>1</td><td>1</td><td>52</td><td>2</td><td>1</td><td>3</td><td>2</td><td>⋯</td><td>2</td><td>2</td><td>2</td><td>1</td><td>4</td><td> 20.65</td><td>1022.95</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>18</th><td>9959-WOFKT</td><td>2</td><td>1</td><td>1</td><td>2</td><td>71</td><td>2</td><td>3</td><td>2</td><td>3</td><td>⋯</td><td>3</td><td>3</td><td>3</td><td>1</td><td>1</td><td>106.70</td><td>7382.25</td><td>0</td><td>4</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>22</th><td>1680-VDCWW</td><td>2</td><td>1</td><td>2</td><td>1</td><td>12</td><td>2</td><td>1</td><td>3</td><td>2</td><td>⋯</td><td>2</td><td>2</td><td>2</td><td>1</td><td>1</td><td> 19.80</td><td> 202.25</td><td>2</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>24</th><td>3638-WEABW</td><td>1</td><td>1</td><td>2</td><td>1</td><td>58</td><td>2</td><td>3</td><td>1</td><td>1</td><td>⋯</td><td>1</td><td>1</td><td>3</td><td>2</td><td>2</td><td> 59.90</td><td>3505.10</td><td>1</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>26</th><td>6865-JZNKO</td><td>1</td><td>1</td><td>1</td><td>1</td><td>30</td><td>2</td><td>1</td><td>1</td><td>3</td><td>⋯</td><td>1</td><td>1</td><td>1</td><td>2</td><td>1</td><td> 55.30</td><td>1530.60</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>29</th><td>5248-YGIJN</td><td>2</td><td>1</td><td>2</td><td>1</td><td>72</td><td>2</td><td>3</td><td>1</td><td>3</td><td>⋯</td><td>3</td><td>3</td><td>3</td><td>2</td><td>2</td><td> 90.25</td><td>6369.45</td><td>1</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>30</th><td>8773-HHUOZ</td><td>1</td><td>1</td><td>1</td><td>2</td><td>17</td><td>2</td><td>1</td><td>1</td><td>1</td><td>⋯</td><td>3</td><td>3</td><td>1</td><td>2</td><td>4</td><td> 64.70</td><td>1093.10</td><td>0</td><td>0</td><td>2</td></tr>\n",
       "\t<tr><th scope=row>31</th><td>3841-NFECX</td><td>1</td><td>2</td><td>2</td><td>1</td><td>71</td><td>2</td><td>3</td><td>2</td><td>3</td><td>⋯</td><td>1</td><td>1</td><td>3</td><td>2</td><td>2</td><td> 96.35</td><td>6766.95</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>33</th><td>6827-IEAUQ</td><td>1</td><td>1</td><td>2</td><td>2</td><td>27</td><td>2</td><td>1</td><td>1</td><td>3</td><td>⋯</td><td>1</td><td>1</td><td>2</td><td>1</td><td>4</td><td> 66.15</td><td>1874.45</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>36</th><td>6234-RAAPL</td><td>1</td><td>1</td><td>2</td><td>2</td><td>72</td><td>2</td><td>3</td><td>2</td><td>3</td><td>⋯</td><td>3</td><td>1</td><td>3</td><td>1</td><td>1</td><td> 99.90</td><td>7251.70</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>38</th><td>6572-ADKRS</td><td>1</td><td>1</td><td>1</td><td>1</td><td>46</td><td>2</td><td>1</td><td>2</td><td>1</td><td>⋯</td><td>1</td><td>1</td><td>1</td><td>2</td><td>2</td><td> 74.80</td><td>3548.30</td><td>3</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>41</th><td>8865-TNMNX</td><td>2</td><td>1</td><td>2</td><td>2</td><td>10</td><td>2</td><td>1</td><td>1</td><td>1</td><td>⋯</td><td>1</td><td>1</td><td>2</td><td>1</td><td>4</td><td> 49.55</td><td> 475.70</td><td>5</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>42</th><td>9489-DEDVP</td><td>1</td><td>1</td><td>2</td><td>2</td><td>70</td><td>2</td><td>3</td><td>1</td><td>3</td><td>⋯</td><td>3</td><td>1</td><td>3</td><td>2</td><td>2</td><td> 69.20</td><td>4872.35</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>43</th><td>9867-JCZSP</td><td>1</td><td>1</td><td>2</td><td>2</td><td>17</td><td>2</td><td>1</td><td>3</td><td>2</td><td>⋯</td><td>2</td><td>2</td><td>2</td><td>1</td><td>4</td><td> 20.75</td><td> 418.25</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>44</th><td>4671-VJLCL</td><td>1</td><td>1</td><td>1</td><td>1</td><td>63</td><td>2</td><td>3</td><td>1</td><td>3</td><td>⋯</td><td>3</td><td>1</td><td>3</td><td>2</td><td>2</td><td> 79.85</td><td>4861.45</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>49</th><td>7639-LIAYI</td><td>2</td><td>1</td><td>1</td><td>1</td><td>52</td><td>2</td><td>3</td><td>1</td><td>3</td><td>⋯</td><td>3</td><td>3</td><td>3</td><td>2</td><td>2</td><td> 79.75</td><td>4217.80</td><td>1</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>50</th><td>2954-PIBKO</td><td>1</td><td>1</td><td>2</td><td>2</td><td>69</td><td>2</td><td>3</td><td>1</td><td>3</td><td>⋯</td><td>1</td><td>1</td><td>3</td><td>2</td><td>2</td><td> 64.15</td><td>4254.10</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>51</th><td>8012-SOUDQ</td><td>1</td><td>2</td><td>1</td><td>1</td><td>43</td><td>2</td><td>3</td><td>2</td><td>1</td><td>⋯</td><td>3</td><td>1</td><td>1</td><td>2</td><td>3</td><td> 90.25</td><td>3838.75</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>53</th><td>6575-SUVOI</td><td>1</td><td>2</td><td>2</td><td>1</td><td>25</td><td>2</td><td>3</td><td>1</td><td>3</td><td>⋯</td><td>3</td><td>1</td><td>1</td><td>2</td><td>2</td><td> 69.50</td><td>1752.65</td><td>4</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>55</th><td>4667-QONEA</td><td>1</td><td>2</td><td>2</td><td>2</td><td>60</td><td>2</td><td>1</td><td>1</td><td>3</td><td>⋯</td><td>1</td><td>3</td><td>2</td><td>2</td><td>2</td><td> 74.85</td><td>4456.35</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>57</th><td>8769-KKTPH</td><td>1</td><td>1</td><td>2</td><td>2</td><td>63</td><td>2</td><td>3</td><td>2</td><td>3</td><td>⋯</td><td>3</td><td>3</td><td>2</td><td>2</td><td>2</td><td> 99.65</td><td>6311.20</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋱</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><th scope=row>6980</th><td>0376-OIWME</td><td>2</td><td>1</td><td>2</td><td>1</td><td>36</td><td>2</td><td>1</td><td>2</td><td>3</td><td>⋯</td><td>3</td><td>3</td><td>1</td><td>2</td><td>3</td><td> 93.60</td><td>3366.05</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>6982</th><td>0218-QNVAS</td><td>2</td><td>1</td><td>2</td><td>2</td><td>71</td><td>2</td><td>3</td><td>2</td><td>1</td><td>⋯</td><td>3</td><td>3</td><td>2</td><td>1</td><td>1</td><td>100.55</td><td>7113.75</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>6984</th><td>0804-YGEQV</td><td>1</td><td>1</td><td>2</td><td>2</td><td>43</td><td>2</td><td>3</td><td>3</td><td>2</td><td>⋯</td><td>2</td><td>2</td><td>2</td><td>2</td><td>1</td><td> 24.45</td><td> 993.15</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>6985</th><td>7164-BPTUT</td><td>2</td><td>1</td><td>1</td><td>2</td><td>57</td><td>2</td><td>3</td><td>1</td><td>3</td><td>⋯</td><td>3</td><td>3</td><td>3</td><td>1</td><td>4</td><td> 89.55</td><td>5012.35</td><td>2</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>6987</th><td>2523-EWWZL</td><td>1</td><td>1</td><td>2</td><td>1</td><td>27</td><td>2</td><td>1</td><td>2</td><td>1</td><td>⋯</td><td>1</td><td>1</td><td>1</td><td>2</td><td>3</td><td> 76.10</td><td>2093.40</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>6990</th><td>0052-YNYOT</td><td>1</td><td>1</td><td>1</td><td>1</td><td>67</td><td>2</td><td>1</td><td>3</td><td>2</td><td>⋯</td><td>2</td><td>2</td><td>2</td><td>1</td><td>3</td><td> 20.55</td><td>1343.40</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>6992</th><td>9586-JGQKH</td><td>1</td><td>1</td><td>2</td><td>1</td><td>64</td><td>2</td><td>3</td><td>2</td><td>1</td><td>⋯</td><td>3</td><td>3</td><td>3</td><td>2</td><td>1</td><td>105.40</td><td>6794.75</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>6993</th><td>4501-VCPFK</td><td>2</td><td>1</td><td>1</td><td>1</td><td>26</td><td>1</td><td>2</td><td>1</td><td>1</td><td>⋯</td><td>1</td><td>1</td><td>1</td><td>1</td><td>3</td><td> 35.75</td><td>1022.50</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>6994</th><td>6075-SLNIL</td><td>2</td><td>1</td><td>1</td><td>1</td><td>38</td><td>2</td><td>3</td><td>2</td><td>1</td><td>⋯</td><td>1</td><td>3</td><td>1</td><td>2</td><td>2</td><td> 95.10</td><td>3691.20</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>6995</th><td>9347-AERRL</td><td>2</td><td>1</td><td>2</td><td>1</td><td>23</td><td>2</td><td>1</td><td>3</td><td>2</td><td>⋯</td><td>2</td><td>2</td><td>2</td><td>1</td><td>2</td><td> 19.30</td><td> 486.20</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>6997</th><td>2274-XUATA</td><td>2</td><td>2</td><td>2</td><td>1</td><td>72</td><td>1</td><td>2</td><td>1</td><td>3</td><td>⋯</td><td>3</td><td>3</td><td>3</td><td>2</td><td>1</td><td> 63.10</td><td>4685.55</td><td>0</td><td>3</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7002</th><td>6691-CCIHA</td><td>1</td><td>1</td><td>2</td><td>1</td><td>62</td><td>2</td><td>3</td><td>1</td><td>3</td><td>⋯</td><td>3</td><td>3</td><td>3</td><td>2</td><td>3</td><td> 84.95</td><td>5150.55</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7003</th><td>1685-BQULA</td><td>1</td><td>1</td><td>1</td><td>1</td><td>40</td><td>2</td><td>3</td><td>2</td><td>1</td><td>⋯</td><td>3</td><td>1</td><td>1</td><td>2</td><td>1</td><td> 93.40</td><td>3756.40</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7004</th><td>9053-EJUNL</td><td>2</td><td>1</td><td>1</td><td>1</td><td>41</td><td>2</td><td>3</td><td>2</td><td>1</td><td>⋯</td><td>3</td><td>1</td><td>1</td><td>2</td><td>3</td><td> 89.20</td><td>3645.75</td><td>3</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7005</th><td>0666-UXTJO</td><td>2</td><td>2</td><td>2</td><td>1</td><td>34</td><td>2</td><td>1</td><td>2</td><td>1</td><td>⋯</td><td>3</td><td>1</td><td>1</td><td>2</td><td>2</td><td> 85.20</td><td>2874.45</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7007</th><td>4807-IZYOZ</td><td>1</td><td>1</td><td>1</td><td>1</td><td>51</td><td>2</td><td>1</td><td>3</td><td>2</td><td>⋯</td><td>2</td><td>2</td><td>3</td><td>1</td><td>1</td><td> 20.65</td><td>1020.75</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7009</th><td>9710-NJERN</td><td>1</td><td>1</td><td>1</td><td>1</td><td>39</td><td>2</td><td>1</td><td>3</td><td>2</td><td>⋯</td><td>2</td><td>2</td><td>3</td><td>1</td><td>4</td><td> 20.15</td><td> 826.00</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7010</th><td>9837-FWLCH</td><td>2</td><td>1</td><td>2</td><td>2</td><td>12</td><td>2</td><td>1</td><td>3</td><td>2</td><td>⋯</td><td>2</td><td>2</td><td>1</td><td>2</td><td>3</td><td> 19.20</td><td> 239.00</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7011</th><td>1699-HPSBG</td><td>2</td><td>1</td><td>1</td><td>1</td><td>12</td><td>2</td><td>1</td><td>1</td><td>1</td><td>⋯</td><td>3</td><td>1</td><td>2</td><td>2</td><td>3</td><td> 59.80</td><td> 727.80</td><td>0</td><td>0</td><td>2</td></tr>\n",
       "\t<tr><th scope=row>7012</th><td>7203-OYKCT</td><td>2</td><td>1</td><td>1</td><td>1</td><td>72</td><td>2</td><td>3</td><td>2</td><td>1</td><td>⋯</td><td>3</td><td>3</td><td>2</td><td>2</td><td>3</td><td>104.95</td><td>7544.30</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7013</th><td>1035-IPQPU</td><td>1</td><td>2</td><td>2</td><td>1</td><td>63</td><td>2</td><td>3</td><td>2</td><td>1</td><td>⋯</td><td>3</td><td>3</td><td>1</td><td>2</td><td>3</td><td>103.50</td><td>6479.40</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7014</th><td>7398-LXGYX</td><td>2</td><td>1</td><td>2</td><td>1</td><td>44</td><td>2</td><td>3</td><td>2</td><td>3</td><td>⋯</td><td>1</td><td>1</td><td>1</td><td>2</td><td>2</td><td> 84.80</td><td>3626.35</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7018</th><td>9281-CEDRU</td><td>1</td><td>1</td><td>2</td><td>1</td><td>68</td><td>2</td><td>1</td><td>1</td><td>1</td><td>⋯</td><td>3</td><td>1</td><td>3</td><td>1</td><td>1</td><td> 64.10</td><td>4326.25</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7021</th><td>3605-JISKB</td><td>2</td><td>2</td><td>2</td><td>1</td><td>55</td><td>2</td><td>3</td><td>1</td><td>3</td><td>⋯</td><td>1</td><td>1</td><td>2</td><td>1</td><td>2</td><td> 60.00</td><td>3316.10</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7023</th><td>9767-FFLEM</td><td>2</td><td>1</td><td>1</td><td>1</td><td>38</td><td>2</td><td>1</td><td>2</td><td>1</td><td>⋯</td><td>1</td><td>1</td><td>1</td><td>2</td><td>2</td><td> 69.50</td><td>2625.25</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7026</th><td>7750-EYXWZ</td><td>1</td><td>1</td><td>1</td><td>1</td><td>12</td><td>1</td><td>2</td><td>1</td><td>1</td><td>⋯</td><td>3</td><td>3</td><td>2</td><td>1</td><td>3</td><td> 60.65</td><td> 743.30</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7027</th><td>2569-WGERO</td><td>1</td><td>1</td><td>1</td><td>1</td><td>72</td><td>2</td><td>1</td><td>3</td><td>2</td><td>⋯</td><td>2</td><td>2</td><td>3</td><td>2</td><td>1</td><td> 21.15</td><td>1419.40</td><td>1</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7028</th><td>6840-RESVB</td><td>2</td><td>1</td><td>2</td><td>2</td><td>24</td><td>2</td><td>3</td><td>1</td><td>3</td><td>⋯</td><td>3</td><td>3</td><td>2</td><td>2</td><td>4</td><td> 84.80</td><td>1990.50</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7030</th><td>4801-JZAZL</td><td>1</td><td>1</td><td>2</td><td>2</td><td>11</td><td>1</td><td>2</td><td>1</td><td>3</td><td>⋯</td><td>1</td><td>1</td><td>1</td><td>2</td><td>3</td><td> 29.60</td><td> 346.45</td><td>0</td><td>0</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>7032</th><td>3186-AJIEK</td><td>2</td><td>1</td><td>1</td><td>1</td><td>66</td><td>2</td><td>1</td><td>2</td><td>3</td><td>⋯</td><td>3</td><td>3</td><td>3</td><td>2</td><td>1</td><td>105.65</td><td>6844.50</td><td>2</td><td>0</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 4203 × 23\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & customerID & gender & SeniorCitizen & Partner & Dependents & tenure & PhoneService & MultipleLines & InternetService & OnlineSecurity & ⋯ & StreamingTV & StreamingMovies & Contract & PaperlessBilling & PaymentMethod & MonthlyCharges & TotalCharges & numAdminTickets & numTechTickets & Churn\\\\\n",
       "  & <chr> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & ⋯ & <int> & <int> & <int> & <int> & <int> & <dbl> & <dbl> & <int> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t2 & 5575-GNVDE & 2 & 1 & 1 & 1 & 34 & 2 & 1 & 1 & 3 & ⋯ & 1 & 1 & 2 & 1 & 4 &  56.95 & 1889.50 & 0 & 0 & 1\\\\\n",
       "\t4 & 7795-CFOCW & 2 & 1 & 1 & 1 & 45 & 1 & 2 & 1 & 3 & ⋯ & 1 & 1 & 2 & 1 & 1 &  42.30 & 1840.75 & 0 & 3 & 1\\\\\n",
       "\t8 & 6713-OKOMC & 1 & 1 & 1 & 1 & 10 & 1 & 2 & 1 & 3 & ⋯ & 1 & 1 & 1 & 1 & 4 &  29.75 &  301.90 & 0 & 0 & 1\\\\\n",
       "\t10 & 6388-TABGU & 2 & 1 & 1 & 2 & 62 & 2 & 1 & 1 & 3 & ⋯ & 1 & 1 & 2 & 1 & 1 &  56.15 & 3487.95 & 0 & 0 & 1\\\\\n",
       "\t11 & 9763-GRSKD & 2 & 1 & 2 & 2 & 13 & 2 & 1 & 1 & 3 & ⋯ & 1 & 1 & 1 & 2 & 4 &  49.95 &  587.45 & 1 & 0 & 1\\\\\n",
       "\t12 & 7469-LKBCI & 2 & 1 & 1 & 1 & 16 & 2 & 1 & 3 & 2 & ⋯ & 2 & 2 & 3 & 1 & 2 &  18.95 &  326.80 & 0 & 0 & 1\\\\\n",
       "\t13 & 8091-TTVAX & 2 & 1 & 2 & 1 & 58 & 2 & 3 & 2 & 1 & ⋯ & 3 & 3 & 2 & 1 & 2 & 100.35 & 5681.10 & 0 & 0 & 1\\\\\n",
       "\t15 & 5129-JLPIS & 2 & 1 & 1 & 1 & 25 & 2 & 1 & 2 & 3 & ⋯ & 3 & 3 & 1 & 2 & 3 & 105.50 & 2686.05 & 0 & 0 & 1\\\\\n",
       "\t16 & 3655-SNQYZ & 1 & 1 & 2 & 2 & 69 & 2 & 3 & 2 & 3 & ⋯ & 3 & 3 & 3 & 1 & 2 & 113.25 & 7895.15 & 0 & 0 & 1\\\\\n",
       "\t17 & 8191-XWSZG & 1 & 1 & 1 & 1 & 52 & 2 & 1 & 3 & 2 & ⋯ & 2 & 2 & 2 & 1 & 4 &  20.65 & 1022.95 & 0 & 0 & 1\\\\\n",
       "\t18 & 9959-WOFKT & 2 & 1 & 1 & 2 & 71 & 2 & 3 & 2 & 3 & ⋯ & 3 & 3 & 3 & 1 & 1 & 106.70 & 7382.25 & 0 & 4 & 1\\\\\n",
       "\t22 & 1680-VDCWW & 2 & 1 & 2 & 1 & 12 & 2 & 1 & 3 & 2 & ⋯ & 2 & 2 & 2 & 1 & 1 &  19.80 &  202.25 & 2 & 0 & 1\\\\\n",
       "\t24 & 3638-WEABW & 1 & 1 & 2 & 1 & 58 & 2 & 3 & 1 & 1 & ⋯ & 1 & 1 & 3 & 2 & 2 &  59.90 & 3505.10 & 1 & 0 & 1\\\\\n",
       "\t26 & 6865-JZNKO & 1 & 1 & 1 & 1 & 30 & 2 & 1 & 1 & 3 & ⋯ & 1 & 1 & 1 & 2 & 1 &  55.30 & 1530.60 & 0 & 0 & 1\\\\\n",
       "\t29 & 5248-YGIJN & 2 & 1 & 2 & 1 & 72 & 2 & 3 & 1 & 3 & ⋯ & 3 & 3 & 3 & 2 & 2 &  90.25 & 6369.45 & 1 & 0 & 1\\\\\n",
       "\t30 & 8773-HHUOZ & 1 & 1 & 1 & 2 & 17 & 2 & 1 & 1 & 1 & ⋯ & 3 & 3 & 1 & 2 & 4 &  64.70 & 1093.10 & 0 & 0 & 2\\\\\n",
       "\t31 & 3841-NFECX & 1 & 2 & 2 & 1 & 71 & 2 & 3 & 2 & 3 & ⋯ & 1 & 1 & 3 & 2 & 2 &  96.35 & 6766.95 & 0 & 0 & 1\\\\\n",
       "\t33 & 6827-IEAUQ & 1 & 1 & 2 & 2 & 27 & 2 & 1 & 1 & 3 & ⋯ & 1 & 1 & 2 & 1 & 4 &  66.15 & 1874.45 & 0 & 0 & 1\\\\\n",
       "\t36 & 6234-RAAPL & 1 & 1 & 2 & 2 & 72 & 2 & 3 & 2 & 3 & ⋯ & 3 & 1 & 3 & 1 & 1 &  99.90 & 7251.70 & 0 & 0 & 1\\\\\n",
       "\t38 & 6572-ADKRS & 1 & 1 & 1 & 1 & 46 & 2 & 1 & 2 & 1 & ⋯ & 1 & 1 & 1 & 2 & 2 &  74.80 & 3548.30 & 3 & 0 & 1\\\\\n",
       "\t41 & 8865-TNMNX & 2 & 1 & 2 & 2 & 10 & 2 & 1 & 1 & 1 & ⋯ & 1 & 1 & 2 & 1 & 4 &  49.55 &  475.70 & 5 & 0 & 1\\\\\n",
       "\t42 & 9489-DEDVP & 1 & 1 & 2 & 2 & 70 & 2 & 3 & 1 & 3 & ⋯ & 3 & 1 & 3 & 2 & 2 &  69.20 & 4872.35 & 0 & 0 & 1\\\\\n",
       "\t43 & 9867-JCZSP & 1 & 1 & 2 & 2 & 17 & 2 & 1 & 3 & 2 & ⋯ & 2 & 2 & 2 & 1 & 4 &  20.75 &  418.25 & 0 & 0 & 1\\\\\n",
       "\t44 & 4671-VJLCL & 1 & 1 & 1 & 1 & 63 & 2 & 3 & 1 & 3 & ⋯ & 3 & 1 & 3 & 2 & 2 &  79.85 & 4861.45 & 0 & 0 & 1\\\\\n",
       "\t49 & 7639-LIAYI & 2 & 1 & 1 & 1 & 52 & 2 & 3 & 1 & 3 & ⋯ & 3 & 3 & 3 & 2 & 2 &  79.75 & 4217.80 & 1 & 0 & 1\\\\\n",
       "\t50 & 2954-PIBKO & 1 & 1 & 2 & 2 & 69 & 2 & 3 & 1 & 3 & ⋯ & 1 & 1 & 3 & 2 & 2 &  64.15 & 4254.10 & 0 & 0 & 1\\\\\n",
       "\t51 & 8012-SOUDQ & 1 & 2 & 1 & 1 & 43 & 2 & 3 & 2 & 1 & ⋯ & 3 & 1 & 1 & 2 & 3 &  90.25 & 3838.75 & 0 & 0 & 1\\\\\n",
       "\t53 & 6575-SUVOI & 1 & 2 & 2 & 1 & 25 & 2 & 3 & 1 & 3 & ⋯ & 3 & 1 & 1 & 2 & 2 &  69.50 & 1752.65 & 4 & 0 & 1\\\\\n",
       "\t55 & 4667-QONEA & 1 & 2 & 2 & 2 & 60 & 2 & 1 & 1 & 3 & ⋯ & 1 & 3 & 2 & 2 & 2 &  74.85 & 4456.35 & 0 & 0 & 1\\\\\n",
       "\t57 & 8769-KKTPH & 1 & 1 & 2 & 2 & 63 & 2 & 3 & 2 & 3 & ⋯ & 3 & 3 & 2 & 2 & 2 &  99.65 & 6311.20 & 0 & 0 & 1\\\\\n",
       "\t⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋱ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t6980 & 0376-OIWME & 2 & 1 & 2 & 1 & 36 & 2 & 1 & 2 & 3 & ⋯ & 3 & 3 & 1 & 2 & 3 &  93.60 & 3366.05 & 0 & 0 & 1\\\\\n",
       "\t6982 & 0218-QNVAS & 2 & 1 & 2 & 2 & 71 & 2 & 3 & 2 & 1 & ⋯ & 3 & 3 & 2 & 1 & 1 & 100.55 & 7113.75 & 0 & 0 & 1\\\\\n",
       "\t6984 & 0804-YGEQV & 1 & 1 & 2 & 2 & 43 & 2 & 3 & 3 & 2 & ⋯ & 2 & 2 & 2 & 2 & 1 &  24.45 &  993.15 & 0 & 0 & 1\\\\\n",
       "\t6985 & 7164-BPTUT & 2 & 1 & 1 & 2 & 57 & 2 & 3 & 1 & 3 & ⋯ & 3 & 3 & 3 & 1 & 4 &  89.55 & 5012.35 & 2 & 0 & 1\\\\\n",
       "\t6987 & 2523-EWWZL & 1 & 1 & 2 & 1 & 27 & 2 & 1 & 2 & 1 & ⋯ & 1 & 1 & 1 & 2 & 3 &  76.10 & 2093.40 & 0 & 0 & 1\\\\\n",
       "\t6990 & 0052-YNYOT & 1 & 1 & 1 & 1 & 67 & 2 & 1 & 3 & 2 & ⋯ & 2 & 2 & 2 & 1 & 3 &  20.55 & 1343.40 & 0 & 0 & 1\\\\\n",
       "\t6992 & 9586-JGQKH & 1 & 1 & 2 & 1 & 64 & 2 & 3 & 2 & 1 & ⋯ & 3 & 3 & 3 & 2 & 1 & 105.40 & 6794.75 & 0 & 0 & 1\\\\\n",
       "\t6993 & 4501-VCPFK & 2 & 1 & 1 & 1 & 26 & 1 & 2 & 1 & 1 & ⋯ & 1 & 1 & 1 & 1 & 3 &  35.75 & 1022.50 & 0 & 0 & 1\\\\\n",
       "\t6994 & 6075-SLNIL & 2 & 1 & 1 & 1 & 38 & 2 & 3 & 2 & 1 & ⋯ & 1 & 3 & 1 & 2 & 2 &  95.10 & 3691.20 & 0 & 0 & 1\\\\\n",
       "\t6995 & 9347-AERRL & 2 & 1 & 2 & 1 & 23 & 2 & 1 & 3 & 2 & ⋯ & 2 & 2 & 2 & 1 & 2 &  19.30 &  486.20 & 0 & 0 & 1\\\\\n",
       "\t6997 & 2274-XUATA & 2 & 2 & 2 & 1 & 72 & 1 & 2 & 1 & 3 & ⋯ & 3 & 3 & 3 & 2 & 1 &  63.10 & 4685.55 & 0 & 3 & 1\\\\\n",
       "\t7002 & 6691-CCIHA & 1 & 1 & 2 & 1 & 62 & 2 & 3 & 1 & 3 & ⋯ & 3 & 3 & 3 & 2 & 3 &  84.95 & 5150.55 & 0 & 0 & 1\\\\\n",
       "\t7003 & 1685-BQULA & 1 & 1 & 1 & 1 & 40 & 2 & 3 & 2 & 1 & ⋯ & 3 & 1 & 1 & 2 & 1 &  93.40 & 3756.40 & 0 & 0 & 1\\\\\n",
       "\t7004 & 9053-EJUNL & 2 & 1 & 1 & 1 & 41 & 2 & 3 & 2 & 1 & ⋯ & 3 & 1 & 1 & 2 & 3 &  89.20 & 3645.75 & 3 & 0 & 1\\\\\n",
       "\t7005 & 0666-UXTJO & 2 & 2 & 2 & 1 & 34 & 2 & 1 & 2 & 1 & ⋯ & 3 & 1 & 1 & 2 & 2 &  85.20 & 2874.45 & 0 & 0 & 1\\\\\n",
       "\t7007 & 4807-IZYOZ & 1 & 1 & 1 & 1 & 51 & 2 & 1 & 3 & 2 & ⋯ & 2 & 2 & 3 & 1 & 1 &  20.65 & 1020.75 & 0 & 0 & 1\\\\\n",
       "\t7009 & 9710-NJERN & 1 & 1 & 1 & 1 & 39 & 2 & 1 & 3 & 2 & ⋯ & 2 & 2 & 3 & 1 & 4 &  20.15 &  826.00 & 0 & 0 & 1\\\\\n",
       "\t7010 & 9837-FWLCH & 2 & 1 & 2 & 2 & 12 & 2 & 1 & 3 & 2 & ⋯ & 2 & 2 & 1 & 2 & 3 &  19.20 &  239.00 & 0 & 0 & 1\\\\\n",
       "\t7011 & 1699-HPSBG & 2 & 1 & 1 & 1 & 12 & 2 & 1 & 1 & 1 & ⋯ & 3 & 1 & 2 & 2 & 3 &  59.80 &  727.80 & 0 & 0 & 2\\\\\n",
       "\t7012 & 7203-OYKCT & 2 & 1 & 1 & 1 & 72 & 2 & 3 & 2 & 1 & ⋯ & 3 & 3 & 2 & 2 & 3 & 104.95 & 7544.30 & 0 & 0 & 1\\\\\n",
       "\t7013 & 1035-IPQPU & 1 & 2 & 2 & 1 & 63 & 2 & 3 & 2 & 1 & ⋯ & 3 & 3 & 1 & 2 & 3 & 103.50 & 6479.40 & 0 & 0 & 1\\\\\n",
       "\t7014 & 7398-LXGYX & 2 & 1 & 2 & 1 & 44 & 2 & 3 & 2 & 3 & ⋯ & 1 & 1 & 1 & 2 & 2 &  84.80 & 3626.35 & 0 & 0 & 1\\\\\n",
       "\t7018 & 9281-CEDRU & 1 & 1 & 2 & 1 & 68 & 2 & 1 & 1 & 1 & ⋯ & 3 & 1 & 3 & 1 & 1 &  64.10 & 4326.25 & 0 & 0 & 1\\\\\n",
       "\t7021 & 3605-JISKB & 2 & 2 & 2 & 1 & 55 & 2 & 3 & 1 & 3 & ⋯ & 1 & 1 & 2 & 1 & 2 &  60.00 & 3316.10 & 0 & 0 & 1\\\\\n",
       "\t7023 & 9767-FFLEM & 2 & 1 & 1 & 1 & 38 & 2 & 1 & 2 & 1 & ⋯ & 1 & 1 & 1 & 2 & 2 &  69.50 & 2625.25 & 0 & 0 & 1\\\\\n",
       "\t7026 & 7750-EYXWZ & 1 & 1 & 1 & 1 & 12 & 1 & 2 & 1 & 1 & ⋯ & 3 & 3 & 2 & 1 & 3 &  60.65 &  743.30 & 0 & 0 & 1\\\\\n",
       "\t7027 & 2569-WGERO & 1 & 1 & 1 & 1 & 72 & 2 & 1 & 3 & 2 & ⋯ & 2 & 2 & 3 & 2 & 1 &  21.15 & 1419.40 & 1 & 0 & 1\\\\\n",
       "\t7028 & 6840-RESVB & 2 & 1 & 2 & 2 & 24 & 2 & 3 & 1 & 3 & ⋯ & 3 & 3 & 2 & 2 & 4 &  84.80 & 1990.50 & 0 & 0 & 1\\\\\n",
       "\t7030 & 4801-JZAZL & 1 & 1 & 2 & 2 & 11 & 1 & 2 & 1 & 3 & ⋯ & 1 & 1 & 1 & 2 & 3 &  29.60 &  346.45 & 0 & 0 & 1\\\\\n",
       "\t7032 & 3186-AJIEK & 2 & 1 & 1 & 1 & 66 & 2 & 1 & 2 & 3 & ⋯ & 3 & 3 & 3 & 2 & 1 & 105.65 & 6844.50 & 2 & 0 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 4203 × 23\n",
       "\n",
       "| <!--/--> | customerID &lt;chr&gt; | gender &lt;int&gt; | SeniorCitizen &lt;int&gt; | Partner &lt;int&gt; | Dependents &lt;int&gt; | tenure &lt;int&gt; | PhoneService &lt;int&gt; | MultipleLines &lt;int&gt; | InternetService &lt;int&gt; | OnlineSecurity &lt;int&gt; | ⋯ ⋯ | StreamingTV &lt;int&gt; | StreamingMovies &lt;int&gt; | Contract &lt;int&gt; | PaperlessBilling &lt;int&gt; | PaymentMethod &lt;int&gt; | MonthlyCharges &lt;dbl&gt; | TotalCharges &lt;dbl&gt; | numAdminTickets &lt;int&gt; | numTechTickets &lt;int&gt; | Churn &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 2 | 5575-GNVDE | 2 | 1 | 1 | 1 | 34 | 2 | 1 | 1 | 3 | ⋯ | 1 | 1 | 2 | 1 | 4 |  56.95 | 1889.50 | 0 | 0 | 1 |\n",
       "| 4 | 7795-CFOCW | 2 | 1 | 1 | 1 | 45 | 1 | 2 | 1 | 3 | ⋯ | 1 | 1 | 2 | 1 | 1 |  42.30 | 1840.75 | 0 | 3 | 1 |\n",
       "| 8 | 6713-OKOMC | 1 | 1 | 1 | 1 | 10 | 1 | 2 | 1 | 3 | ⋯ | 1 | 1 | 1 | 1 | 4 |  29.75 |  301.90 | 0 | 0 | 1 |\n",
       "| 10 | 6388-TABGU | 2 | 1 | 1 | 2 | 62 | 2 | 1 | 1 | 3 | ⋯ | 1 | 1 | 2 | 1 | 1 |  56.15 | 3487.95 | 0 | 0 | 1 |\n",
       "| 11 | 9763-GRSKD | 2 | 1 | 2 | 2 | 13 | 2 | 1 | 1 | 3 | ⋯ | 1 | 1 | 1 | 2 | 4 |  49.95 |  587.45 | 1 | 0 | 1 |\n",
       "| 12 | 7469-LKBCI | 2 | 1 | 1 | 1 | 16 | 2 | 1 | 3 | 2 | ⋯ | 2 | 2 | 3 | 1 | 2 |  18.95 |  326.80 | 0 | 0 | 1 |\n",
       "| 13 | 8091-TTVAX | 2 | 1 | 2 | 1 | 58 | 2 | 3 | 2 | 1 | ⋯ | 3 | 3 | 2 | 1 | 2 | 100.35 | 5681.10 | 0 | 0 | 1 |\n",
       "| 15 | 5129-JLPIS | 2 | 1 | 1 | 1 | 25 | 2 | 1 | 2 | 3 | ⋯ | 3 | 3 | 1 | 2 | 3 | 105.50 | 2686.05 | 0 | 0 | 1 |\n",
       "| 16 | 3655-SNQYZ | 1 | 1 | 2 | 2 | 69 | 2 | 3 | 2 | 3 | ⋯ | 3 | 3 | 3 | 1 | 2 | 113.25 | 7895.15 | 0 | 0 | 1 |\n",
       "| 17 | 8191-XWSZG | 1 | 1 | 1 | 1 | 52 | 2 | 1 | 3 | 2 | ⋯ | 2 | 2 | 2 | 1 | 4 |  20.65 | 1022.95 | 0 | 0 | 1 |\n",
       "| 18 | 9959-WOFKT | 2 | 1 | 1 | 2 | 71 | 2 | 3 | 2 | 3 | ⋯ | 3 | 3 | 3 | 1 | 1 | 106.70 | 7382.25 | 0 | 4 | 1 |\n",
       "| 22 | 1680-VDCWW | 2 | 1 | 2 | 1 | 12 | 2 | 1 | 3 | 2 | ⋯ | 2 | 2 | 2 | 1 | 1 |  19.80 |  202.25 | 2 | 0 | 1 |\n",
       "| 24 | 3638-WEABW | 1 | 1 | 2 | 1 | 58 | 2 | 3 | 1 | 1 | ⋯ | 1 | 1 | 3 | 2 | 2 |  59.90 | 3505.10 | 1 | 0 | 1 |\n",
       "| 26 | 6865-JZNKO | 1 | 1 | 1 | 1 | 30 | 2 | 1 | 1 | 3 | ⋯ | 1 | 1 | 1 | 2 | 1 |  55.30 | 1530.60 | 0 | 0 | 1 |\n",
       "| 29 | 5248-YGIJN | 2 | 1 | 2 | 1 | 72 | 2 | 3 | 1 | 3 | ⋯ | 3 | 3 | 3 | 2 | 2 |  90.25 | 6369.45 | 1 | 0 | 1 |\n",
       "| 30 | 8773-HHUOZ | 1 | 1 | 1 | 2 | 17 | 2 | 1 | 1 | 1 | ⋯ | 3 | 3 | 1 | 2 | 4 |  64.70 | 1093.10 | 0 | 0 | 2 |\n",
       "| 31 | 3841-NFECX | 1 | 2 | 2 | 1 | 71 | 2 | 3 | 2 | 3 | ⋯ | 1 | 1 | 3 | 2 | 2 |  96.35 | 6766.95 | 0 | 0 | 1 |\n",
       "| 33 | 6827-IEAUQ | 1 | 1 | 2 | 2 | 27 | 2 | 1 | 1 | 3 | ⋯ | 1 | 1 | 2 | 1 | 4 |  66.15 | 1874.45 | 0 | 0 | 1 |\n",
       "| 36 | 6234-RAAPL | 1 | 1 | 2 | 2 | 72 | 2 | 3 | 2 | 3 | ⋯ | 3 | 1 | 3 | 1 | 1 |  99.90 | 7251.70 | 0 | 0 | 1 |\n",
       "| 38 | 6572-ADKRS | 1 | 1 | 1 | 1 | 46 | 2 | 1 | 2 | 1 | ⋯ | 1 | 1 | 1 | 2 | 2 |  74.80 | 3548.30 | 3 | 0 | 1 |\n",
       "| 41 | 8865-TNMNX | 2 | 1 | 2 | 2 | 10 | 2 | 1 | 1 | 1 | ⋯ | 1 | 1 | 2 | 1 | 4 |  49.55 |  475.70 | 5 | 0 | 1 |\n",
       "| 42 | 9489-DEDVP | 1 | 1 | 2 | 2 | 70 | 2 | 3 | 1 | 3 | ⋯ | 3 | 1 | 3 | 2 | 2 |  69.20 | 4872.35 | 0 | 0 | 1 |\n",
       "| 43 | 9867-JCZSP | 1 | 1 | 2 | 2 | 17 | 2 | 1 | 3 | 2 | ⋯ | 2 | 2 | 2 | 1 | 4 |  20.75 |  418.25 | 0 | 0 | 1 |\n",
       "| 44 | 4671-VJLCL | 1 | 1 | 1 | 1 | 63 | 2 | 3 | 1 | 3 | ⋯ | 3 | 1 | 3 | 2 | 2 |  79.85 | 4861.45 | 0 | 0 | 1 |\n",
       "| 49 | 7639-LIAYI | 2 | 1 | 1 | 1 | 52 | 2 | 3 | 1 | 3 | ⋯ | 3 | 3 | 3 | 2 | 2 |  79.75 | 4217.80 | 1 | 0 | 1 |\n",
       "| 50 | 2954-PIBKO | 1 | 1 | 2 | 2 | 69 | 2 | 3 | 1 | 3 | ⋯ | 1 | 1 | 3 | 2 | 2 |  64.15 | 4254.10 | 0 | 0 | 1 |\n",
       "| 51 | 8012-SOUDQ | 1 | 2 | 1 | 1 | 43 | 2 | 3 | 2 | 1 | ⋯ | 3 | 1 | 1 | 2 | 3 |  90.25 | 3838.75 | 0 | 0 | 1 |\n",
       "| 53 | 6575-SUVOI | 1 | 2 | 2 | 1 | 25 | 2 | 3 | 1 | 3 | ⋯ | 3 | 1 | 1 | 2 | 2 |  69.50 | 1752.65 | 4 | 0 | 1 |\n",
       "| 55 | 4667-QONEA | 1 | 2 | 2 | 2 | 60 | 2 | 1 | 1 | 3 | ⋯ | 1 | 3 | 2 | 2 | 2 |  74.85 | 4456.35 | 0 | 0 | 1 |\n",
       "| 57 | 8769-KKTPH | 1 | 1 | 2 | 2 | 63 | 2 | 3 | 2 | 3 | ⋯ | 3 | 3 | 2 | 2 | 2 |  99.65 | 6311.20 | 0 | 0 | 1 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋱ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| 6980 | 0376-OIWME | 2 | 1 | 2 | 1 | 36 | 2 | 1 | 2 | 3 | ⋯ | 3 | 3 | 1 | 2 | 3 |  93.60 | 3366.05 | 0 | 0 | 1 |\n",
       "| 6982 | 0218-QNVAS | 2 | 1 | 2 | 2 | 71 | 2 | 3 | 2 | 1 | ⋯ | 3 | 3 | 2 | 1 | 1 | 100.55 | 7113.75 | 0 | 0 | 1 |\n",
       "| 6984 | 0804-YGEQV | 1 | 1 | 2 | 2 | 43 | 2 | 3 | 3 | 2 | ⋯ | 2 | 2 | 2 | 2 | 1 |  24.45 |  993.15 | 0 | 0 | 1 |\n",
       "| 6985 | 7164-BPTUT | 2 | 1 | 1 | 2 | 57 | 2 | 3 | 1 | 3 | ⋯ | 3 | 3 | 3 | 1 | 4 |  89.55 | 5012.35 | 2 | 0 | 1 |\n",
       "| 6987 | 2523-EWWZL | 1 | 1 | 2 | 1 | 27 | 2 | 1 | 2 | 1 | ⋯ | 1 | 1 | 1 | 2 | 3 |  76.10 | 2093.40 | 0 | 0 | 1 |\n",
       "| 6990 | 0052-YNYOT | 1 | 1 | 1 | 1 | 67 | 2 | 1 | 3 | 2 | ⋯ | 2 | 2 | 2 | 1 | 3 |  20.55 | 1343.40 | 0 | 0 | 1 |\n",
       "| 6992 | 9586-JGQKH | 1 | 1 | 2 | 1 | 64 | 2 | 3 | 2 | 1 | ⋯ | 3 | 3 | 3 | 2 | 1 | 105.40 | 6794.75 | 0 | 0 | 1 |\n",
       "| 6993 | 4501-VCPFK | 2 | 1 | 1 | 1 | 26 | 1 | 2 | 1 | 1 | ⋯ | 1 | 1 | 1 | 1 | 3 |  35.75 | 1022.50 | 0 | 0 | 1 |\n",
       "| 6994 | 6075-SLNIL | 2 | 1 | 1 | 1 | 38 | 2 | 3 | 2 | 1 | ⋯ | 1 | 3 | 1 | 2 | 2 |  95.10 | 3691.20 | 0 | 0 | 1 |\n",
       "| 6995 | 9347-AERRL | 2 | 1 | 2 | 1 | 23 | 2 | 1 | 3 | 2 | ⋯ | 2 | 2 | 2 | 1 | 2 |  19.30 |  486.20 | 0 | 0 | 1 |\n",
       "| 6997 | 2274-XUATA | 2 | 2 | 2 | 1 | 72 | 1 | 2 | 1 | 3 | ⋯ | 3 | 3 | 3 | 2 | 1 |  63.10 | 4685.55 | 0 | 3 | 1 |\n",
       "| 7002 | 6691-CCIHA | 1 | 1 | 2 | 1 | 62 | 2 | 3 | 1 | 3 | ⋯ | 3 | 3 | 3 | 2 | 3 |  84.95 | 5150.55 | 0 | 0 | 1 |\n",
       "| 7003 | 1685-BQULA | 1 | 1 | 1 | 1 | 40 | 2 | 3 | 2 | 1 | ⋯ | 3 | 1 | 1 | 2 | 1 |  93.40 | 3756.40 | 0 | 0 | 1 |\n",
       "| 7004 | 9053-EJUNL | 2 | 1 | 1 | 1 | 41 | 2 | 3 | 2 | 1 | ⋯ | 3 | 1 | 1 | 2 | 3 |  89.20 | 3645.75 | 3 | 0 | 1 |\n",
       "| 7005 | 0666-UXTJO | 2 | 2 | 2 | 1 | 34 | 2 | 1 | 2 | 1 | ⋯ | 3 | 1 | 1 | 2 | 2 |  85.20 | 2874.45 | 0 | 0 | 1 |\n",
       "| 7007 | 4807-IZYOZ | 1 | 1 | 1 | 1 | 51 | 2 | 1 | 3 | 2 | ⋯ | 2 | 2 | 3 | 1 | 1 |  20.65 | 1020.75 | 0 | 0 | 1 |\n",
       "| 7009 | 9710-NJERN | 1 | 1 | 1 | 1 | 39 | 2 | 1 | 3 | 2 | ⋯ | 2 | 2 | 3 | 1 | 4 |  20.15 |  826.00 | 0 | 0 | 1 |\n",
       "| 7010 | 9837-FWLCH | 2 | 1 | 2 | 2 | 12 | 2 | 1 | 3 | 2 | ⋯ | 2 | 2 | 1 | 2 | 3 |  19.20 |  239.00 | 0 | 0 | 1 |\n",
       "| 7011 | 1699-HPSBG | 2 | 1 | 1 | 1 | 12 | 2 | 1 | 1 | 1 | ⋯ | 3 | 1 | 2 | 2 | 3 |  59.80 |  727.80 | 0 | 0 | 2 |\n",
       "| 7012 | 7203-OYKCT | 2 | 1 | 1 | 1 | 72 | 2 | 3 | 2 | 1 | ⋯ | 3 | 3 | 2 | 2 | 3 | 104.95 | 7544.30 | 0 | 0 | 1 |\n",
       "| 7013 | 1035-IPQPU | 1 | 2 | 2 | 1 | 63 | 2 | 3 | 2 | 1 | ⋯ | 3 | 3 | 1 | 2 | 3 | 103.50 | 6479.40 | 0 | 0 | 1 |\n",
       "| 7014 | 7398-LXGYX | 2 | 1 | 2 | 1 | 44 | 2 | 3 | 2 | 3 | ⋯ | 1 | 1 | 1 | 2 | 2 |  84.80 | 3626.35 | 0 | 0 | 1 |\n",
       "| 7018 | 9281-CEDRU | 1 | 1 | 2 | 1 | 68 | 2 | 1 | 1 | 1 | ⋯ | 3 | 1 | 3 | 1 | 1 |  64.10 | 4326.25 | 0 | 0 | 1 |\n",
       "| 7021 | 3605-JISKB | 2 | 2 | 2 | 1 | 55 | 2 | 3 | 1 | 3 | ⋯ | 1 | 1 | 2 | 1 | 2 |  60.00 | 3316.10 | 0 | 0 | 1 |\n",
       "| 7023 | 9767-FFLEM | 2 | 1 | 1 | 1 | 38 | 2 | 1 | 2 | 1 | ⋯ | 1 | 1 | 1 | 2 | 2 |  69.50 | 2625.25 | 0 | 0 | 1 |\n",
       "| 7026 | 7750-EYXWZ | 1 | 1 | 1 | 1 | 12 | 1 | 2 | 1 | 1 | ⋯ | 3 | 3 | 2 | 1 | 3 |  60.65 |  743.30 | 0 | 0 | 1 |\n",
       "| 7027 | 2569-WGERO | 1 | 1 | 1 | 1 | 72 | 2 | 1 | 3 | 2 | ⋯ | 2 | 2 | 3 | 2 | 1 |  21.15 | 1419.40 | 1 | 0 | 1 |\n",
       "| 7028 | 6840-RESVB | 2 | 1 | 2 | 2 | 24 | 2 | 3 | 1 | 3 | ⋯ | 3 | 3 | 2 | 2 | 4 |  84.80 | 1990.50 | 0 | 0 | 1 |\n",
       "| 7030 | 4801-JZAZL | 1 | 1 | 2 | 2 | 11 | 1 | 2 | 1 | 3 | ⋯ | 1 | 1 | 1 | 2 | 3 |  29.60 |  346.45 | 0 | 0 | 1 |\n",
       "| 7032 | 3186-AJIEK | 2 | 1 | 1 | 1 | 66 | 2 | 1 | 2 | 3 | ⋯ | 3 | 3 | 3 | 2 | 1 | 105.65 | 6844.50 | 2 | 0 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "     customerID gender SeniorCitizen Partner Dependents tenure PhoneService\n",
       "2    5575-GNVDE 2      1             1       1          34     2           \n",
       "4    7795-CFOCW 2      1             1       1          45     1           \n",
       "8    6713-OKOMC 1      1             1       1          10     1           \n",
       "10   6388-TABGU 2      1             1       2          62     2           \n",
       "11   9763-GRSKD 2      1             2       2          13     2           \n",
       "12   7469-LKBCI 2      1             1       1          16     2           \n",
       "13   8091-TTVAX 2      1             2       1          58     2           \n",
       "15   5129-JLPIS 2      1             1       1          25     2           \n",
       "16   3655-SNQYZ 1      1             2       2          69     2           \n",
       "17   8191-XWSZG 1      1             1       1          52     2           \n",
       "18   9959-WOFKT 2      1             1       2          71     2           \n",
       "22   1680-VDCWW 2      1             2       1          12     2           \n",
       "24   3638-WEABW 1      1             2       1          58     2           \n",
       "26   6865-JZNKO 1      1             1       1          30     2           \n",
       "29   5248-YGIJN 2      1             2       1          72     2           \n",
       "30   8773-HHUOZ 1      1             1       2          17     2           \n",
       "31   3841-NFECX 1      2             2       1          71     2           \n",
       "33   6827-IEAUQ 1      1             2       2          27     2           \n",
       "36   6234-RAAPL 1      1             2       2          72     2           \n",
       "38   6572-ADKRS 1      1             1       1          46     2           \n",
       "41   8865-TNMNX 2      1             2       2          10     2           \n",
       "42   9489-DEDVP 1      1             2       2          70     2           \n",
       "43   9867-JCZSP 1      1             2       2          17     2           \n",
       "44   4671-VJLCL 1      1             1       1          63     2           \n",
       "49   7639-LIAYI 2      1             1       1          52     2           \n",
       "50   2954-PIBKO 1      1             2       2          69     2           \n",
       "51   8012-SOUDQ 1      2             1       1          43     2           \n",
       "53   6575-SUVOI 1      2             2       1          25     2           \n",
       "55   4667-QONEA 1      2             2       2          60     2           \n",
       "57   8769-KKTPH 1      1             2       2          63     2           \n",
       "⋮    ⋮          ⋮      ⋮             ⋮       ⋮          ⋮      ⋮           \n",
       "6980 0376-OIWME 2      1             2       1          36     2           \n",
       "6982 0218-QNVAS 2      1             2       2          71     2           \n",
       "6984 0804-YGEQV 1      1             2       2          43     2           \n",
       "6985 7164-BPTUT 2      1             1       2          57     2           \n",
       "6987 2523-EWWZL 1      1             2       1          27     2           \n",
       "6990 0052-YNYOT 1      1             1       1          67     2           \n",
       "6992 9586-JGQKH 1      1             2       1          64     2           \n",
       "6993 4501-VCPFK 2      1             1       1          26     1           \n",
       "6994 6075-SLNIL 2      1             1       1          38     2           \n",
       "6995 9347-AERRL 2      1             2       1          23     2           \n",
       "6997 2274-XUATA 2      2             2       1          72     1           \n",
       "7002 6691-CCIHA 1      1             2       1          62     2           \n",
       "7003 1685-BQULA 1      1             1       1          40     2           \n",
       "7004 9053-EJUNL 2      1             1       1          41     2           \n",
       "7005 0666-UXTJO 2      2             2       1          34     2           \n",
       "7007 4807-IZYOZ 1      1             1       1          51     2           \n",
       "7009 9710-NJERN 1      1             1       1          39     2           \n",
       "7010 9837-FWLCH 2      1             2       2          12     2           \n",
       "7011 1699-HPSBG 2      1             1       1          12     2           \n",
       "7012 7203-OYKCT 2      1             1       1          72     2           \n",
       "7013 1035-IPQPU 1      2             2       1          63     2           \n",
       "7014 7398-LXGYX 2      1             2       1          44     2           \n",
       "7018 9281-CEDRU 1      1             2       1          68     2           \n",
       "7021 3605-JISKB 2      2             2       1          55     2           \n",
       "7023 9767-FFLEM 2      1             1       1          38     2           \n",
       "7026 7750-EYXWZ 1      1             1       1          12     1           \n",
       "7027 2569-WGERO 1      1             1       1          72     2           \n",
       "7028 6840-RESVB 2      1             2       2          24     2           \n",
       "7030 4801-JZAZL 1      1             2       2          11     1           \n",
       "7032 3186-AJIEK 2      1             1       1          66     2           \n",
       "     MultipleLines InternetService OnlineSecurity ⋯ StreamingTV StreamingMovies\n",
       "2    1             1               3              ⋯ 1           1              \n",
       "4    2             1               3              ⋯ 1           1              \n",
       "8    2             1               3              ⋯ 1           1              \n",
       "10   1             1               3              ⋯ 1           1              \n",
       "11   1             1               3              ⋯ 1           1              \n",
       "12   1             3               2              ⋯ 2           2              \n",
       "13   3             2               1              ⋯ 3           3              \n",
       "15   1             2               3              ⋯ 3           3              \n",
       "16   3             2               3              ⋯ 3           3              \n",
       "17   1             3               2              ⋯ 2           2              \n",
       "18   3             2               3              ⋯ 3           3              \n",
       "22   1             3               2              ⋯ 2           2              \n",
       "24   3             1               1              ⋯ 1           1              \n",
       "26   1             1               3              ⋯ 1           1              \n",
       "29   3             1               3              ⋯ 3           3              \n",
       "30   1             1               1              ⋯ 3           3              \n",
       "31   3             2               3              ⋯ 1           1              \n",
       "33   1             1               3              ⋯ 1           1              \n",
       "36   3             2               3              ⋯ 3           1              \n",
       "38   1             2               1              ⋯ 1           1              \n",
       "41   1             1               1              ⋯ 1           1              \n",
       "42   3             1               3              ⋯ 3           1              \n",
       "43   1             3               2              ⋯ 2           2              \n",
       "44   3             1               3              ⋯ 3           1              \n",
       "49   3             1               3              ⋯ 3           3              \n",
       "50   3             1               3              ⋯ 1           1              \n",
       "51   3             2               1              ⋯ 3           1              \n",
       "53   3             1               3              ⋯ 3           1              \n",
       "55   1             1               3              ⋯ 1           3              \n",
       "57   3             2               3              ⋯ 3           3              \n",
       "⋮    ⋮             ⋮               ⋮              ⋱ ⋮           ⋮              \n",
       "6980 1             2               3              ⋯ 3           3              \n",
       "6982 3             2               1              ⋯ 3           3              \n",
       "6984 3             3               2              ⋯ 2           2              \n",
       "6985 3             1               3              ⋯ 3           3              \n",
       "6987 1             2               1              ⋯ 1           1              \n",
       "6990 1             3               2              ⋯ 2           2              \n",
       "6992 3             2               1              ⋯ 3           3              \n",
       "6993 2             1               1              ⋯ 1           1              \n",
       "6994 3             2               1              ⋯ 1           3              \n",
       "6995 1             3               2              ⋯ 2           2              \n",
       "6997 2             1               3              ⋯ 3           3              \n",
       "7002 3             1               3              ⋯ 3           3              \n",
       "7003 3             2               1              ⋯ 3           1              \n",
       "7004 3             2               1              ⋯ 3           1              \n",
       "7005 1             2               1              ⋯ 3           1              \n",
       "7007 1             3               2              ⋯ 2           2              \n",
       "7009 1             3               2              ⋯ 2           2              \n",
       "7010 1             3               2              ⋯ 2           2              \n",
       "7011 1             1               1              ⋯ 3           1              \n",
       "7012 3             2               1              ⋯ 3           3              \n",
       "7013 3             2               1              ⋯ 3           3              \n",
       "7014 3             2               3              ⋯ 1           1              \n",
       "7018 1             1               1              ⋯ 3           1              \n",
       "7021 3             1               3              ⋯ 1           1              \n",
       "7023 1             2               1              ⋯ 1           1              \n",
       "7026 2             1               1              ⋯ 3           3              \n",
       "7027 1             3               2              ⋯ 2           2              \n",
       "7028 3             1               3              ⋯ 3           3              \n",
       "7030 2             1               3              ⋯ 1           1              \n",
       "7032 1             2               3              ⋯ 3           3              \n",
       "     Contract PaperlessBilling PaymentMethod MonthlyCharges TotalCharges\n",
       "2    2        1                4              56.95         1889.50     \n",
       "4    2        1                1              42.30         1840.75     \n",
       "8    1        1                4              29.75          301.90     \n",
       "10   2        1                1              56.15         3487.95     \n",
       "11   1        2                4              49.95          587.45     \n",
       "12   3        1                2              18.95          326.80     \n",
       "13   2        1                2             100.35         5681.10     \n",
       "15   1        2                3             105.50         2686.05     \n",
       "16   3        1                2             113.25         7895.15     \n",
       "17   2        1                4              20.65         1022.95     \n",
       "18   3        1                1             106.70         7382.25     \n",
       "22   2        1                1              19.80          202.25     \n",
       "24   3        2                2              59.90         3505.10     \n",
       "26   1        2                1              55.30         1530.60     \n",
       "29   3        2                2              90.25         6369.45     \n",
       "30   1        2                4              64.70         1093.10     \n",
       "31   3        2                2              96.35         6766.95     \n",
       "33   2        1                4              66.15         1874.45     \n",
       "36   3        1                1              99.90         7251.70     \n",
       "38   1        2                2              74.80         3548.30     \n",
       "41   2        1                4              49.55          475.70     \n",
       "42   3        2                2              69.20         4872.35     \n",
       "43   2        1                4              20.75          418.25     \n",
       "44   3        2                2              79.85         4861.45     \n",
       "49   3        2                2              79.75         4217.80     \n",
       "50   3        2                2              64.15         4254.10     \n",
       "51   1        2                3              90.25         3838.75     \n",
       "53   1        2                2              69.50         1752.65     \n",
       "55   2        2                2              74.85         4456.35     \n",
       "57   2        2                2              99.65         6311.20     \n",
       "⋮    ⋮        ⋮                ⋮             ⋮              ⋮           \n",
       "6980 1        2                3              93.60         3366.05     \n",
       "6982 2        1                1             100.55         7113.75     \n",
       "6984 2        2                1              24.45          993.15     \n",
       "6985 3        1                4              89.55         5012.35     \n",
       "6987 1        2                3              76.10         2093.40     \n",
       "6990 2        1                3              20.55         1343.40     \n",
       "6992 3        2                1             105.40         6794.75     \n",
       "6993 1        1                3              35.75         1022.50     \n",
       "6994 1        2                2              95.10         3691.20     \n",
       "6995 2        1                2              19.30          486.20     \n",
       "6997 3        2                1              63.10         4685.55     \n",
       "7002 3        2                3              84.95         5150.55     \n",
       "7003 1        2                1              93.40         3756.40     \n",
       "7004 1        2                3              89.20         3645.75     \n",
       "7005 1        2                2              85.20         2874.45     \n",
       "7007 3        1                1              20.65         1020.75     \n",
       "7009 3        1                4              20.15          826.00     \n",
       "7010 1        2                3              19.20          239.00     \n",
       "7011 2        2                3              59.80          727.80     \n",
       "7012 2        2                3             104.95         7544.30     \n",
       "7013 1        2                3             103.50         6479.40     \n",
       "7014 1        2                2              84.80         3626.35     \n",
       "7018 3        1                1              64.10         4326.25     \n",
       "7021 2        1                2              60.00         3316.10     \n",
       "7023 1        2                2              69.50         2625.25     \n",
       "7026 2        1                3              60.65          743.30     \n",
       "7027 3        2                1              21.15         1419.40     \n",
       "7028 2        2                4              84.80         1990.50     \n",
       "7030 1        2                3              29.60          346.45     \n",
       "7032 3        2                1             105.65         6844.50     \n",
       "     numAdminTickets numTechTickets Churn\n",
       "2    0               0              1    \n",
       "4    0               3              1    \n",
       "8    0               0              1    \n",
       "10   0               0              1    \n",
       "11   1               0              1    \n",
       "12   0               0              1    \n",
       "13   0               0              1    \n",
       "15   0               0              1    \n",
       "16   0               0              1    \n",
       "17   0               0              1    \n",
       "18   0               4              1    \n",
       "22   2               0              1    \n",
       "24   1               0              1    \n",
       "26   0               0              1    \n",
       "29   1               0              1    \n",
       "30   0               0              2    \n",
       "31   0               0              1    \n",
       "33   0               0              1    \n",
       "36   0               0              1    \n",
       "38   3               0              1    \n",
       "41   5               0              1    \n",
       "42   0               0              1    \n",
       "43   0               0              1    \n",
       "44   0               0              1    \n",
       "49   1               0              1    \n",
       "50   0               0              1    \n",
       "51   0               0              1    \n",
       "53   4               0              1    \n",
       "55   0               0              1    \n",
       "57   0               0              1    \n",
       "⋮    ⋮               ⋮              ⋮    \n",
       "6980 0               0              1    \n",
       "6982 0               0              1    \n",
       "6984 0               0              1    \n",
       "6985 2               0              1    \n",
       "6987 0               0              1    \n",
       "6990 0               0              1    \n",
       "6992 0               0              1    \n",
       "6993 0               0              1    \n",
       "6994 0               0              1    \n",
       "6995 0               0              1    \n",
       "6997 0               3              1    \n",
       "7002 0               0              1    \n",
       "7003 0               0              1    \n",
       "7004 3               0              1    \n",
       "7005 0               0              1    \n",
       "7007 0               0              1    \n",
       "7009 0               0              1    \n",
       "7010 0               0              1    \n",
       "7011 0               0              2    \n",
       "7012 0               0              1    \n",
       "7013 0               0              1    \n",
       "7014 0               0              1    \n",
       "7018 0               0              1    \n",
       "7021 0               0              1    \n",
       "7023 0               0              1    \n",
       "7026 0               0              1    \n",
       "7027 1               0              1    \n",
       "7028 0               0              1    \n",
       "7030 0               0              1    \n",
       "7032 2               0              1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create logistic regression model\n",
    "model <- glm(Churn ~ ., family = \"binomial\", data = train)\n",
    "\n",
    "# 4. Model Evaluation: Evaluate model performance on the test set\n",
    "predicted_probs <- predict(model, newdata = test, type = \"response\")\n",
    "predicted_class <- ifelse(predicted_probs > 0.7, 1, 0) # Threshold set at 0.7, can be further tuned\n",
    "\n",
    "conf_matrix <- confusionMatrix(factor(predicted_class), factor(test$Churn))\n",
    "print(conf_matrix)\n",
    "\n",
    "# 5. Predict Churn Probability: Use the model to predict churn probabilities for the entire dataset\n",
    "churn_probs <- predict(model, newdata = data_filtered, type = \"response\")\n",
    "\n",
    "# 6. Set a Threshold: Using ROC curve to find optimal threshold\n",
    "roc_obj <- roc(data_filtered$Churn, churn_probs)\n",
    "youdens_index <- roc_obj$sensitivities + roc_obj$specificities - 1\n",
    "optimal_threshold <- roc_obj$thresholds[which.max(youdens_index)]\n",
    "\n",
    "# 7. Identify High-Risk Customers: Classify customers based on the threshold\n",
    "high_risk_customers <- data[ifelse(churn_probs > optimal_threshold, TRUE, FALSE),]\n",
    "\n",
    "# Print high-risk customers\n",
    "high_risk_customers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP (True Positives) = 1277: customers who were predicted to churn and actually churned.\n",
    "TN (True Negatives) = 486: customers who were predicted not to churn and actually did not churn.\n",
    "FP (False Positives) = 74: customers who were predicted to churn but did not churn.\n",
    "FN (False Negatives) = 272: customers who were predicted not to churn but actually churned.\n",
    "Accuracy: 0.8359 (95% CI: 0.8194, 0.8515)\n",
    "The model's accuracy is 83.59%, meaning it correctly classified around 83.59% of the test dataset. The 95% confidence interval for the accuracy ranges from 81.94% to 85.15%.\n",
    "\n",
    "No Information Rate (NIR): 0.7345\n",
    "The NIR is the accuracy that could be achieved by always predicting the most frequent class. In this case, the most frequent class is '1' (not churn), with a proportion of 73.45%.\n",
    "\n",
    "P-Value [Acc > NIR]: < 2.2e-16\n",
    "The p-value tests whether the model's accuracy is significantly better than the NIR. A small p-value (e.g., < 0.05) indicates that the model's accuracy is significantly better than the NIR. In this case, the p-value is very small (< 2.2e-16), so the model is significantly better than always predicting the most frequent class.\n",
    "\n",
    "Kappa: 0.622\n",
    "Cohen's Kappa measures the agreement between the model's predictions and the actual outcomes, accounting for the agreement that occurs by chance. A Kappa value of 1 indicates perfect agreement, while a value of 0 indicates agreement by chance. A Kappa of 0.622 suggests a good level of agreement between the predictions and the actual outcomes.\n",
    "\n",
    "Sensitivity (Recall): 0.8679\n",
    "Sensitivity, also known as recall or true positive rate (TPR), measures the proportion of actual positives (churn) that were correctly identified by the model. In this case, the model correctly identified 85% of the customers who churned.\n",
    "\n",
    "Specificity: 0.8244 \n",
    "Specificity, also known as the true negative rate (TNR), measures the proportion of actual negatives (non-churn) that were correctly identified by the model. In this case, the model correctly identified 83.6% of the customers who did not churn.\n",
    "\n",
    "Positive Predictive Value (PPV, Precision): 0.6412  \n",
    "PPV, also known as precision, measures the proportion of true positives out of all the positive predictions made by the model. In this case, 65.21% of the customers predicted to churn actually churned.\n",
    "\n",
    "Negative Predictive Value (NPV): 0.9452\n",
    "NPV measures the proportion of true negatives out of all the negative predictions made by the model. In this case, 93.91% of the customers predicted not to churn actually did not churn.\n",
    "\n",
    "Overall, the logistic regression model has good performance, with an accuracy of 83.59%, a Kappa of 0.622"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now proceed to predict high-risk customers using another model - CART decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction    0    1\n",
       "         0  374  154\n",
       "         1  186 1395\n",
       "                                          \n",
       "               Accuracy : 0.8388          \n",
       "                 95% CI : (0.8224, 0.8542)\n",
       "    No Information Rate : 0.7345          \n",
       "    P-Value [Acc > NIR] : < 2e-16         \n",
       "                                          \n",
       "                  Kappa : 0.579           \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.09272         \n",
       "                                          \n",
       "            Sensitivity : 0.6679          \n",
       "            Specificity : 0.9006          \n",
       "         Pos Pred Value : 0.7083          \n",
       "         Neg Pred Value : 0.8824          \n",
       "             Prevalence : 0.2655          \n",
       "         Detection Rate : 0.1773          \n",
       "   Detection Prevalence : 0.2504          \n",
       "      Balanced Accuracy : 0.7842          \n",
       "                                          \n",
       "       'Positive' Class : 0               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Inf\n"
     ]
    }
   ],
   "source": [
    "# 5. Train the model: Decision Tree\n",
    "model <- rpart(Churn ~ ., data = train, method = \"class\", control = rpart.control(minsplit = 20, cp = 0.001))\n",
    "\n",
    "# 6. Make predictions\n",
    "predictions <- predict(model, newdata = test, type = \"class\")\n",
    "\n",
    "# 7. Evaluate the model\n",
    "# Ensure that predictions and test_data$Churn have the same levels\n",
    "predictions <- factor(predictions, levels = c(0, 1))\n",
    "test$Churn <- factor(test$Churn, levels = c(0, 1))\n",
    "\n",
    "# Calculate confusion matrix\n",
    "confusionMatrix(predictions, test$Churn)\n",
    "\n",
    "# Calculate the misclassification rate\n",
    "misclassification_rate <- mean(predictions != test$Churn)\n",
    "\n",
    "# Estimate the log-likelihood assuming a binomial distribution\n",
    "n <- nrow(test)\n",
    "log_likelihood <- sum(log(dbinom(as.numeric(test$Churn), size = 1, prob = misclassification_rate)))\n",
    "\n",
    "# Compute the AIC score\n",
    "num_parameters <- length(model$frame$var) - 1\n",
    "AIC_score <- -2 * log_likelihood + 2 * num_parameters\n",
    "\n",
    "# Print the AIC score\n",
    "print(AIC_score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the evaluation metrics of CART decision tree vs the logistic regression:\n",
    "\n",
    "CART Decision Tree:\n",
    "\n",
    "Accuracy: 0.8487 \n",
    "\n",
    "Kappa: 0.5978\n",
    "\n",
    "Sensitivity (Recall): 0.6589\n",
    "\n",
    "Specificity: 0.9174\n",
    "\n",
    "Positive Predictive Value (Precision): 0.7425\n",
    "\n",
    "Negative Predictive Value: 0.8815\n",
    "\n",
    "Logistic Regression:\n",
    "\n",
    "\n",
    "Accuracy: 0.8397\n",
    "\n",
    "Kappa: 0.6254\n",
    "\n",
    "Sensitivity (Recall): 0.8500\n",
    "\n",
    "Specificity: 0.8360\n",
    "\n",
    "Positive Predictive Value (Precision): 0.6521\n",
    "\n",
    "Negative Predictive Value: 0.9391\n",
    "\n",
    "Comparison:\n",
    "\n",
    "The CART decision tree model has a slightly higher accuracy (84.87% vs. 83.97%).\n",
    "\n",
    "The logistic regression model has a higher Kappa (0.6254 vs. 0.5978), indicating better agreement between predictions and actual outcomes after accounting for chance.\n",
    "\n",
    "The logistic regression model has higher sensitivity (0.8500 vs. 0.6589), which means it's better at identifying customers who churn.\n",
    "\n",
    "The CART decision tree model has higher specificity (0.9174 vs. 0.8360), which means it's better at identifying customers who do not churn.\n",
    "\n",
    "The CART decision tree model has a higher PPV or precision (0.7425 vs. 0.6521), meaning a higher proportion of true positives among positive predictions.\n",
    "\n",
    "The logistic regression model has a higher NPV (0.9391 vs. 0.8815), meaning a higher proportion of true negatives among negative predictions.\n",
    "\n",
    "Overall, both models have their strengths and weaknesses, and the choice between them would depend on the specific business context and objectives. If correctly identifying customers who churn is more important, the logistic regression model may be more suitable. On the other hand, if correctly identifying customers who do not churn is more important, the CART decision tree model may be preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“labs do not fit even at cex 0.15, there may be some overplotting”\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>pdf:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{pdf:} 2"
      ],
      "text/markdown": [
       "**pdf:** 2"
      ],
      "text/plain": [
       "pdf \n",
       "  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train$Churn <- as.factor(train$Churn)\n",
    "levels(train$Churn) <- make.names(levels(train$Churn))\n",
    "\n",
    "\n",
    "# Set up cross-validation settings\n",
    "fitControl <- trainControl(method = \"cv\",\n",
    "                           number = 10,\n",
    "                           returnResamp = \"all\",\n",
    "                           savePredictions = TRUE,\n",
    "                           classProbs = TRUE)\n",
    "\n",
    "# Train the decision tree model using cross-validation\n",
    "model_cv <- train(Churn ~ .,\n",
    "                 data = train,\n",
    "                 method = \"rpart\",\n",
    "                 trControl = fitControl,\n",
    "                 tuneLength = 10)\n",
    "\n",
    "# Prune the tree\n",
    "model_pruned <- prune(model_cv$finalModel, cp = model_cv$bestTune$cp)      \n",
    "\n",
    "# Set the margins of the plot\n",
    "par(mar = c(1, 1, 1, 1))\n",
    "\n",
    "# Save the plot as a PNG image with custom dimensions\n",
    "png(\"decision_tree_plot.png\", width = 2000, height = 2000, res = 600)\n",
    "\n",
    "# Plot the decision tree\n",
    "rpart.plot(model, \n",
    "           type = 4,       # Plot type\n",
    "           extra = 100,    # Display the percentage of observations in each node\n",
    "           box.palette = \"auto\",   # Automatic coloring of nodes\n",
    "           branch.lty = 3,         # Branch line style\n",
    "           main = \"Decision Tree\", # Title of the plot\n",
    "           cex = 0.15,             # Text scaling factor\n",
    "           fallen.leaves = TRUE,   # Place leaves at the bottom of the plot\n",
    "           uniform = TRUE,         # Uniform spacing of nodes\n",
    "           compress = TRUE,        # Compress the tree horizontally if possible\n",
    "           )           # Margin around the plot\n",
    "\n",
    "# Close the PNG device\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t1612 obs. of  23 variables:\n",
      " $ customerID      : chr  \"3668-QPYBK\" \"7795-CFOCW\" \"1452-KIOVK\" \"6713-OKOMC\" ...\n",
      " $ gender          : int  2 2 2 1 2 2 2 2 1 2 ...\n",
      " $ SeniorCitizen   : int  1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ Partner         : int  1 1 1 1 1 2 1 1 2 2 ...\n",
      " $ Dependents      : int  1 1 2 1 2 2 1 1 2 1 ...\n",
      " $ tenure          : int  2 45 22 10 62 13 16 25 10 12 ...\n",
      " $ PhoneService    : int  2 1 2 1 2 2 2 2 2 2 ...\n",
      " $ MultipleLines   : int  1 2 3 2 1 1 1 1 1 1 ...\n",
      " $ InternetService : int  1 1 2 1 1 1 3 2 1 3 ...\n",
      " $ OnlineSecurity  : int  3 3 1 3 3 3 2 3 1 2 ...\n",
      " $ OnlineBackup    : int  3 1 3 1 3 1 2 1 1 2 ...\n",
      " $ DeviceProtection: int  1 3 1 1 1 1 2 3 3 2 ...\n",
      " $ TechSupport     : int  1 3 1 1 1 1 2 3 3 2 ...\n",
      " $ StreamingTV     : int  1 1 3 1 1 1 2 3 1 2 ...\n",
      " $ StreamingMovies : int  1 1 1 1 1 1 2 3 1 2 ...\n",
      " $ Contract        : Factor w/ 3 levels \"1\",\"2\",\"3\": 1 2 1 1 2 1 3 1 1 2 ...\n",
      " $ PaperlessBilling: Factor w/ 2 levels \"1\",\"2\": 2 1 2 1 1 2 1 2 1 1 ...\n",
      " $ PaymentMethod   : int  4 1 2 4 1 4 2 3 2 1 ...\n",
      " $ MonthlyCharges  : num  53.9 42.3 89.1 29.8 56.1 ...\n",
      " $ TotalCharges    : num  108 1841 1949 302 3488 ...\n",
      " $ numAdminTickets : int  0 0 0 0 0 1 0 0 0 2 ...\n",
      " $ numTechTickets  : int  0 3 0 0 0 0 0 0 0 0 ...\n",
      " $ Churn           : int  2 1 1 1 1 1 1 1 2 1 ...\n"
     ]
    }
   ],
   "source": [
    "# Add the predictions to the test data\n",
    "test$PredictedChurn <- predictions\n",
    "\n",
    "# Filter high-risk customers\n",
    "high_risk_customers <- test%>% filter(PredictedChurn == 1)\n",
    "\n",
    "# Add customerID to the test data\n",
    "test$customerID <- data$customerID[-split]\n",
    "\n",
    "# Get customer information for high-risk customers\n",
    "high_risk_customers_info <- data %>% filter(customerID %in% high_risk_customers$customerID)\n",
    "\n",
    "str(high_risk_customers_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
